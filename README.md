 # Panel Data Hausman Test Monte Carlo Simulation
 Trough a Monte Carlo simulation study I try to investigate the performance under misspecification [Heteroskedasticity(on the individual specific error term and on the remainder error term) and serial correlation] of the Durbin-Wu-Hausman test (and its robust formulation, found in Wooldridge 2002) for correlated effects with panel data.
 ## 1 - DGP of the Variable X
I generate the explanatory variable X as the sum of a between (or cross–sectional or permanent) component <a href="http://www.codecogs.com/eqnedit.php?latex=\inline&space;\LARGE&space;\xi_{i}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\inline&space;\LARGE&space;\xi_{i}" title="\LARGE \xi_{i}" /></a> and a within (or time series or time varying) component <a href="http://www.codecogs.com/eqnedit.php?latex=\inline&space;\LARGE&space;\xi_{it}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\inline&space;\LARGE&space;\xi_{it}" title="\LARGE \xi_{it}" /></a>. We suppose that the between component <a href="http://www.codecogs.com/eqnedit.php?latex=\inline&space;\LARGE&space;\xi_{i}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\inline&space;\LARGE&space;\xi_{i}" title="\LARGE \xi_{i}" /></a> is itself the sum of an exogenous sub-component <a href="http://www.codecogs.com/eqnedit.php?latex=\inline&space;\LARGE&space;\xi_{i}^{e}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\inline&space;\LARGE&space;\xi_{i}^{e}" title="\LARGE \xi_{i}^{e}" /></a> and a correlated on <a href="http://www.codecogs.com/eqnedit.php?latex=\inline&space;\LARGE&space;\xi_{i}^{c}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\inline&space;\LARGE&space;\xi_{i}^{c}" title="\LARGE \xi_{i}^{c}" /></a>  (i.e., correlated with the individual effect <a href="http://www.codecogs.com/eqnedit.php?latex=\inline&space;\LARGE&space;\alpha_{i}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\inline&space;\LARGE&space;\alpha_{i}" title="\LARGE \alpha_{i}" /></a> in the regression model). And we have:











<a href="http://www.codecogs.com/eqnedit.php?latex=\inline&space;\large&space;%======================================================================&space;\chapter{Simulação&space;Monte&space;Carlo}&space;%&space;Write&space;in&space;your&space;own&space;chapter&space;title&space;\label{montecar}&space;%\lhead{&space;\emph{Introdução}}&space;%&space;Write&space;in&space;your&space;own&space;chapter&space;title&space;to&space;set&space;the&space;page&space;header&space;\fancyhead[LE,RO]{\textbf{\emph{\textcolor{ineblue}{Simulação&space;Monte&space;Carlo}}}}&space;\fancyhead[RE,LO]{\textbf{\textcolor{ineblue}\thepage}}&space;%======================================================================&space;%======================================================================&space;\section{Calibragem&space;da&space;Simulação}&space;%======================================================================&space;Em&space;todos&space;cenários&space;simulados&space;queremos&space;que&space;o&space;modelo&space;seja&space;o&space;mais&space;perfeito&space;possível,&space;em&space;que&space;as&space;únicas&space;distorções&space;do&space;teste&space;sejam&space;as&space;unicamente&space;causadas&space;pela&space;violação&space;das&space;hipóteses&space;de&space;ausência&space;de&space;autocorrelação&space;e/ou&space;heterocedasticidade.&space;Assim&space;impomos&space;que&space;$VAR(x_{it})=1$&space;e&space;que&space;$\sigma^2=\sigma_{\mu_i}^{2}&plus;\sigma_{v_{it}}^{2}=1$&space;em&space;todas&space;as&space;simulações,&space;além&space;do&space;mais,&space;a&space;contribuição&space;da&space;variância&space;dos&space;efeitos&space;individuais&space;para&space;a&space;variância&space;total&space;é&space;sempre&space;a&space;mesma&space;que&space;a&space;contribuição&space;dos&space;erros&space;idiossincráticos&space;logo&space;$\kappa=0.5$.&space;De&space;forma&space;a&space;calibrar&space;as&space;componentes&space;da&space;variável&space;\textbf{x},&space;e&space;porque&space;como&space;vimos&space;queremos&space;que&space;$VAR(x_{it})=VAR(\xi_{i})&plus;VAR(\xi_{it})=1$,&space;com&space;$VAR(\xi_{i})=\sigma_{\mu_i}^{2}=\kappa$,&space;$VAR(\xi_{it})=\sigma_{v_{it}}^{2}=\sigma_{\varphi_{it}}^{2}=(1-\kappa)$&space;e&space;$v_{it}\sim&space;N(0,\sigma_{v_{it}}^{2})$,&space;o&space;que&space;implica&space;que&space;existe&space;uma&space;relação&space;entre&space;as&space;variâncias&space;de&space;$\eta_i$&space;e&space;$\eta_{it}$&space;com&space;os&space;parâmetros&space;$\delta$&space;e&space;$\vartheta$,&space;respectivamente,&space;do&space;seguinte&space;modo:&space;\begin{equation*}&space;\sigma_{\eta_{it}}^2=(1-\vartheta^2)\sigma_{v_{it}}^{2}=(1-\vartheta^2)\sigma_{\varphi_{it}}^{2}\quad&space;\text{e}\quad&space;\sigma_{\eta_{i}}^2=(1-\delta^2)\sigma_{\mu_i}^{2}&space;\end{equation*}&space;e&space;garantimos&space;que&space;$VAR(x_{it})=1$&space;para&space;quaisquer&space;valores&space;de&space;$\delta$&space;e&space;$\vartheta$.&space;Em&space;todas&space;as&space;simulações&space;$\vartheta=0$\footnote{Não&space;queremos&space;a&space;existência&space;de&space;um&space;erro&space;de&space;medida&space;nos&space;modelos}&space;e&space;$\delta$&space;toma&space;os&space;valores&space;0,&space;0.25,&space;0.5,&space;0.75,&space;quando&space;$\delta=0$&space;temos&space;a&space;hipótese&space;nula&space;do&space;teste&space;de&space;Hausman&space;(1978),&space;onde,&space;ao&space;longo&space;dos&space;vários&space;cenários&space;simulados&space;podemos&space;aferir&space;do&space;comportamento&space;da&space;sua&space;\emph{dimensão}.&space;Se&space;$\delta\neq0$&space;temos&space;a&space;hipótese&space;alternativa&space;do&space;teste&space;que&space;é&space;usada&space;para&space;quantificar&space;a&space;sua&space;\emph{potência&space;}.&space;Com&space;esta&space;configuração&space;os&space;enviesamentos&space;ficam:\quad&space;$BIAS_B=\delta$&space;e&space;$BIAS_W=0$.&space;Para&space;estudar&space;o&space;comportamentos&space;do&space;teste&space;quando&space;existe&space;autocorrelação&space;no&space;erro&space;idiossincrático&space;adoptamos&space;um&space;modelo&space;tipo&space;(LILLARD&space;e&space;WILLIS&space;(1978)&space;CITAR),&space;que&space;já&space;foi&space;bastante&space;utilizado&space;por&space;Baltagi&space;e&space;outros(CITAR).&space;Juntamente&space;com&space;as&space;configuraçãoes&space;anteriores&space;temos:&space;$v_{it}=\rho&space;v_{it-1}&plus;\epsilon_{it}$,&space;com&space;$v_{i0}=\epsilon_{i0}/\sqrt{1-\rho^2}$,&space;$\epsilon_{it}\sim&space;N(0,\sigma_{\epsilon_{it}}^{2})$,&space;e&space;$v_{it}\sim&space;N(0,(1-\kappa))$,&space;e&space;temos:&space;$\sigma_{v_{it}}^2=\epsilon_{it}^{2}/(1-\rho^2)\Rightarrow\sigma_{\epsilon_{it}}^{2}=(1-\kappa)(1-\rho^2)$.&space;É&space;de&space;salientar&space;que&space;este&space;modelo&space;tem&space;três&space;fontes&space;de&space;``persistência''&space;conhecidas:&space;\begin{enumerate}&space;\item&space;Persistência&space;da&space;variável&space;explicativa&space;devida&space;à&space;sua&space;componente&space;\emph{Within}&space;que&space;tem&space;uma&space;sub-componente&space;definida&space;como&space;sendo&space;um&space;processo&space;$AR(\rho)$;&space;\item&space;Presença&space;do&space;efeito&space;individual&space;não&space;observado&space;(que&space;não&space;varia&space;com&space;o&space;tempo)&space;que&space;introduz&space;uma&space;fonte&space;de&space;persistência&space;fixa&space;em&space;todo&space;o&space;painel,&space;devido&space;à&space;presença&space;do&space;mesmo&space;indivíduo&space;em&space;todos&space;os&space;períodos&space;de&space;tempo;&space;\item&space;Aquela&space;associada&space;a&space;$\rho>0$,&space;o&space;que&space;induz&space;uma&space;persitência&space;transitória&space;devido&space;ao&space;carácter&space;estacionário&space;do&space;erro&space;idiossincrático,&space;em&space;todos&space;os&space;cenários&space;simulados&space;$\rho$&space;toma&space;valores&space;0,&space;0.25,&space;0.5,&space;0.75.&space;\end{enumerate}&space;%======================================================================&space;\subsection{Modelos&space;Simulados}&space;%======================================================================&space;O&space;modelo&space;base&space;(benchmark)&space;e&space;as&space;suas&space;variantes&space;com&space;autocorrelação&space;e/ou&space;heterocedasticidade&space;a&space;usar&space;nos&space;vários&space;cenários&space;simulados&space;é:\footnote{Consideramos&space;sempre&space;que&space;$\ell=1$&space;ou&space;seja&space;$\eta_{it}\sim&space;AR(1)$}:&space;\begin{itemize}&space;\item&space;i)&space;Benchmark&space;\begin{align*}&space;y_{it}&=5&plus;0.5x_{it}&plus;u_{it}\\&space;u_{it}&=\mu_i&plus;v_{it}\\&space;x_{it}&=\eta_i&plus;\delta\mu_i&plus;\omega_0\eta_{it}&plus;\omega_1\eta_{it-1}\\&space;\sigma^2&=\sigma_{\mu_i}^{2}&plus;\sigma_{v_{it}}^{2}=1\\&space;\kappa&=\frac{\sigma_{\mu_i}^{2}}{\sigma^2}\\&space;\eta_i&\sim&space;N(0,(1-\delta^2)\kappa)\\&space;\eta_{it}&\sim&space;N(0,(1-\kappa))\\&space;\mu_i&\sim&space;N(0,\kappa)\\&space;v_{it}&\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;ii)&space;Erro&space;idiossincrático&space;com&space;Autocorrelação&space;de&space;1\textordfeminine\xspace&space;ordem&space;\begin{align*}&space;v_{it}&=0.5v_{it-1}&plus;\epsilon_{it}\\&space;\epsilon_{it}&\sim&space;N(0,\sigma_{\epsilon_{it}}^{2})\\&space;\sigma_{\epsilon_{it}}^{2}&=(1-\kappa)(1-\rho^2)&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;iii)&space;Erro&space;idiossincrático&space;com&space;Heterocedasticidade&space;``cross-section''\footnote{Mais&space;conhecida&space;como&space;heterocedasticidade&space;de&space;painel.},&space;em&space;que&space;as&space;variâncias&space;mudam&space;com&space;a&space;unidade&space;``cross-section''&space;("`shift"'&space;na&space;variância),&space;ou&space;seja,&space;$\sigma_{v_{it}}^{2}$&space;é&space;definida&space;como:&space;\begin{align*}&space;\sigma_{v_{it}}^{2}&\sim&space;N(0,(1-\kappa))\quad\text{para}\quad&space;i=1,\cdots,\left\lfloor&space;N/2\right\rfloor\\&space;\sigma_{v_{it}}^{2}&\sim&space;N(0,1.5)\quad\text{para}\quad&space;i=\left\lfloor&space;N/2\right\rfloor,\cdots,N&space;\end{align*}&space;com&space;$\left\lfloor&space;q\right\rfloor$&space;a&space;parte&space;inteira&space;de&space;\textbf{q}.&space;\end{itemize}&space;\begin{itemize}&space;\item&space;iv)&space;Heterocedasticidade&space;causada&space;pela&space;variável&space;explicativa:&space;\begin{align*}&space;w_{it}=v_{it}(1&plus;\lambda&space;x_{it})\quad\text{com}\quad&space;v_{it}\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;v)&space;Heterocedasticidade&space;causada&space;pela&space;variável&space;$\mu_i$&space;\begin{align*}&space;w_{it}=v_{it}\mu_i\quad\text{com}\quad&space;v_{it}\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;vi)&space;Heterocedasticidade&space;causada&space;pela&space;componente&space;within&space;de&space;\textbf{X}:&space;\begin{align*}&space;w_{it}=v_{it}(1&plus;\lambda\eta_{it})\quad\text{com}\quad&space;v_{it}\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;A&space;matriz&space;de&space;variâncias-covariâncias&space;da&space;componente&space;de&space;erro&space;com&space;heterocedasticidade&space;e/ou&space;autocorrelação&space;por&space;exemplo&space;para&space;\textbf{T=3}&space;vem:&space;\begin{equation*}&space;A_i=&space;\begin{pmatrix}&space;\sigma^{2}_{\mu}&plus;x_i\sigma^{2}_{v}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{1,2}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{1,3}&space;\\&space;\sigma^{2}_{\mu}&plus;\phi_{2,1}&space;&&space;\sigma^{2}_{\mu}&plus;x_i\sigma^{2}_{v}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{2,3}\\&space;\sigma^{2}_{\mu}&plus;\phi_{3,1}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{3,2}&space;&&space;\sigma^{2}_{\mu}&plus;x_i\sigma^{2}_{v}&space;\end{pmatrix}&space;\end{equation*}&space;\begin{equation*}&space;\Omega=&space;\begin{pmatrix}&space;A_1&space;&&space;0&space;&&space;0\\&space;0&space;&&space;A_2&space;&&space;0&space;\\&space;0&space;&&space;0&space;&&space;A_3&space;\end{pmatrix}&space;\end{equation*}&space;A&space;escolha&space;das&space;dimensões&space;CS&space;e&space;TS&space;para&space;as&space;nossas&space;simulações&space;segue&space;alguns&space;trabalhos&space;com&space;dados&space;de&space;painel&space;(nomeadamente&space;CITAR&space;autores&space;e&space;papers).&space;Ahn&space;e&space;Moon&space;(2001)&space;examinaram&space;teoricamente&space;as&space;propriedades&space;assimptóticas&space;dos&space;estimadores&space;Within,&space;GLS&space;e&space;do&space;teste&space;de&space;Hausman&space;standard&space;para&space;paineis&space;com&space;elevadas&space;unidades&space;CS&space;e&space;TS.&space;Os&space;autores&space;usaram&space;modelos&space;com&space;regressores&space;que&space;incluem&space;tendências&space;determinísticas&space;na&space;média&space;assim&space;como&space;regressores&space;invariantes&space;no&space;tempo.&space;Para&space;os&space;autores&space;o&space;estimador&space;Within&space;é&space;tão&space;eficiente&space;como&space;o&space;GLS&space;neste&space;contexto,&space;apesar&space;desta&space;equivalência&space;assimptótica,&space;a&space;estatística&space;de&space;Hausman&space;está&space;bem&space;definida&space;e&space;segue&space;assimptóticamente&space;uma&space;distribuição&space;do&space;$\chi^2$&space;sob&space;a&space;hipótese&space;de&space;efeitos&space;aleatórios.&space;Acabam&space;por&space;concluir&space;que&space;as&space;taxas&space;de&space;convergência&space;dos&space;estimadores&space;e&space;da&space;estatística&space;de&space;teste&space;são&space;sensiveis&space;aos&space;DGP's&space;usados.&space;Apesar&space;de&space;existirem&space;diferentes&space;taxas&space;de&space;convergência,&space;os&space;estimadores&space;são&space;consistentes&space;e&space;assimptóticamente&space;normais&space;sob&space;a&space;hipótese&space;de&space;efeitos&space;aleatórios.&space;A&space;estatística&space;de&space;Hausman&space;Standard&space;está&space;bem&space;definida&space;apesar&space;de&space;os&space;dois&space;estimadores&space;serem&space;assimptóticamente&space;idênticos&space;sob&space;uma&space;sequência&space;de&space;hipóteses&space;alternativas.&space;Assim&space;a&space;lição&space;que&space;se&space;retira&space;deste&space;estudo&space;é&space;que&space;a&space;teoria&space;assimptótica&space;quando&space;$N,T\rightarrow\infty$&space;é&space;muito&space;mais&space;sensível&space;aos&space;DGP's&space;usados&space;do&space;que&space;quando&space;$N\rightarrow\infty$&space;ou&space;$T\rightarrow\infty$.&space;Para&space;o&space;nosso&space;estudo&space;resolvemos&space;usar&space;as&space;seguintes&space;dimensões:&space;N=(25,&space;50,&space;100)&space;e&space;T=(5,&space;10,&space;20,&space;30).&space;No&space;que&space;respeita&space;à&space;estimação&space;das&space;variâncias&space;da&space;componente&space;de&space;erro&space;usamos&space;o&space;método&space;de&space;Ammemyia\footnote{O&space;package&space;``plm''&space;do&space;\normalsize{\R}&space;tem&space;um&space;pequeno&space;bug&space;ao&space;dar&space;erro&space;no&space;teste&space;de&space;hausman&space;quando&space;as&space;variâncias&space;são&space;negativas&space;e&space;usamos&space;o&space;método&space;implementado&space;por&space;defeito:&space;Swamy&space;e&space;Arora.}&space;em&space;todas&space;as&space;simulações,&space;suportamos&space;esta&space;escolha&space;no&space;estudo&space;de&space;Maddala&space;e&space;Mount&space;(1973)&space;que&space;mostraram&space;através&space;de&space;simulação&space;que&space;a&space;escolha&space;de&space;um&space;particular&space;método&space;para&space;as&space;estimar&space;não&space;tem&space;impactos&space;significativos&space;nas&space;propriedades&space;dos&space;estimadores&space;dos&space;coeficientes&space;no&space;segundo&space;passo&space;do&space;FGLS&space;(veja-se&space;tambêm&space;Taylor&space;(1980)&space;que&space;dá&space;um&space;exemplo&space;teórico),&space;isto&space;não&space;quer&space;dizer&space;que&space;substituindo&space;o&space;verdadeiro&space;valor&space;de&space;$\theta$&space;por&space;uma&space;sua&space;estimativa&space;não&space;tenha&space;consequências.&space;Não&space;afecta&space;as&space;propriedades&space;assimptóticas&space;do&space;FGLS&space;,&space;mas&space;tem&space;influência&space;nas&space;suas&space;propriedades&space;em&space;amostras&space;finitas,&space;o&space;GLS&space;é&space;não&space;enviesado,&space;o&space;FGLS&space;não&space;o&space;é,&space;a&space;não&space;ser&space;em&space;circunstâncias&space;muito&space;particulares(&space;ver&space;Baltagi,&space;Matyas,&space;Sevestre).&space;Recentemente&space;Vasnev&space;(2009)&space;estudou&space;a&space;sensibilidade&space;dos&space;estimadores&space;de&space;efeitos&space;aleatórios&space;num&space;modelo&space;``One-way''&space;com&space;componentes&space;no&space;erro&space;ao&space;estimador&space;do&space;primeiro&space;passo&space;das&space;variâncias,&space;ilustrando-a&space;com&space;um&space;pequeno&space;estudo&space;de&space;simulação&space;e&space;mostra&space;que&space;o&space;enviesamento&space;e&space;as&space;variâncias&space;dos&space;estimadores&space;do&space;primeiro&space;e&space;segundo&space;passo&space;estão&space;ligados&space;através&space;de&space;uma&space;estatística&space;de&space;sensibilidade.&space;Conjuntamente&space;com&space;a&space;independência&space;do&space;estimador&space;do&space;primeiro&space;passo,&space;a&space;estatística&space;de&space;sensibilidade&space;tem&space;propriedades&space;específicas,&space;o&space;que&space;faz&space;com&space;que&space;o&space;estimador&space;do&space;segundo&space;passo&space;seja&space;independente&space;do&space;enviesamento&space;do&space;estimador&space;do&space;primeiro&space;passo,&space;o&space;que&space;torna&space;a&space;variância&space;do&space;estimador&space;do&space;segundo&space;passo&space;insensível&space;aos&space;ganhos&space;de&space;eficiencia&space;do&space;estimador&space;do&space;primeiro&space;passo.&space;Este&space;estudo&space;explica&space;as&space;conclusões&space;de&space;Maddala&space;e&space;mount&space;(1973)&space;e&space;por&space;conseguinte&space;a&space;nossa&space;escolha&space;do&space;método&space;para&space;estimar&space;as&space;variâncias&space;da&space;componente&space;de&space;erro.&space;%======================================================================&space;\section{Apresentação&space;dos&space;Resultados}&space;%&space;Write&space;in&space;your&space;own&space;chapter&space;title&space;%======================================================================&space;%======================================================================&space;\subsection{Dimensão&space;e&space;Potência&space;de&space;um&space;Teste}&space;%======================================================================&space;É&space;sabido&space;da&space;teoria&space;estatística&space;elementar&space;que&space;a&space;\textbf{\emph{dimensão}}&space;de&space;um&space;teste&space;assenta&space;na&space;taxa&space;de&space;rejeição&space;da&space;hipótese&space;nula&space;($H_0$)&space;quando&space;esta&space;é&space;verdadeira,&space;e&space;a&space;\textbf{\emph{potência}}&space;implica&space;a&space;sua&space;taxa&space;de&space;rejeição&space;quando&space;a&space;hipótese&space;alternativa&space;é&space;verdadeira.&space;Normalmente&space;definimos&space;a&space;dimensão&space;do&space;teste&space;num&space;nível&space;de&space;significância&space;específico:&space;$\alpha$,&space;por&space;exemplo&space;o&space;valor&space;crítico&space;a&space;5\%&space;para&space;uma&space;distribuição&space;Normal&space;(teste&space;bilateral)&space;é&space;igual&space;a&space;1.95.&space;Basicamente&space;a&space;ideia&space;é&space;fazer&space;uma&space;decisão&space;errada&space;a&space;um&space;nível&space;de&space;5\%.&space;definir&space;uma&space;dimensão&space;pequena&space;quer&space;dizer&space;que&space;queremos&space;ser&space;mais&space;conservadores&space;ou&space;não&space;queremos&space;errar&space;de&space;todo,&space;mas&space;ao&space;mesmo&space;tempo&space;tambêm&space;implica&space;que&space;a&space;potência&space;do&space;teste&space;virá&space;reduzida.&space;Inicialmente&space;definimos&space;uma&space;dimensão&space;para&space;o&space;teste&space;de&space;$\alpha\%$,&space;contudo&space;(especialmente&space;em&space;amostras&space;finitas),&space;um&space;teste&space;não&space;dá&space;exactamente&space;a&space;dimensão&space;pretendida&space;de&space;$\alpha\%$.&space;Se&space;um&space;teste&space;\emph{\textbf{sobre-rejeita}}&space;$H_0$&space;quando&space;esta&space;é&space;verdadeira,&space;dizemos&space;que&space;o&space;teste&space;sofre&space;de&space;\textbf{\emph{Oversize-Distortion}}.&space;O&space;caso&space;oposto&space;é&space;o&space;de&space;\textbf{\emph{Undesize-Distortion}}.&space;Geralmente&space;um&space;teste&space;que&space;\textbf{\emph{sub-rejeita}}&space;é&space;aceitável&space;desde&space;que&space;este&space;simplesmente&space;implique&space;cometer&space;menos&space;erros.&space;O&space;problema&space;de&space;\textbf{\emph{sobre-rejeição}}&space;torna-se&space;sério,&space;dado&space;que&space;o&space;teste&space;usualmente&space;rejeita&space;$H_0$&space;muitas&space;mais&space;vezes&space;que&space;o&space;necessário,&space;mesmo&space;sendo&space;esta&space;verdadeira.&space;%======================================================================&space;\subsection{Tabelas&space;ou&space;Gráficos?}\label{tabougraf}&space;%======================================================================&space;Uma&space;das&space;maiores&space;dificuldades&space;com&space;que&space;nos&space;deparamos&space;quando&space;fazemos&space;estudos&space;de&space;simulação&space;para&space;estudar&space;o&space;comportamento&space;de&space;testes&space;estatísticos,&space;além&space;dos&space;problemas&space;de&space;implementação&space;computacional,&space;é&space;o&space;de&space;sintetizar&space;e&space;interpretar&space;os&space;resultados&space;obtidos.&space;Podemos&space;usar&space;tabelas,&space;mas&space;com&space;a&space;quantidade&space;de&space;parâmetros&space;que&space;podem&space;variar&space;e&space;a&space;sempre&space;imposta&space;limitação&space;de&space;páginas&space;para&space;escrever&space;um&space;artigo&space;de&space;jornal&space;ou&space;mesmo&space;uma&space;dissertação&space;de&space;mestrado,&space;as&space;conclusões&space;a&space;retirar&space;das&space;tabelas&space;são&space;complicadas.&space;A&space;solução&space;é&space;a&space;de&space;apresentar&space;os&space;resultados&space;graficamente,&space;permitindo&space;uma&space;análise&space;expedita&space;e&space;intuitiva&space;dos&space;mesmos.&space;Os&space;resultados&space;obtidos&space;na&space;simulação&space;são&space;apresentados&space;usando&space;o&space;método&space;gráfico&space;explicado&space;no&space;excelente&space;trabalho&space;de&space;Davidson&space;e&space;MacKinnon&space;(1998).&space;Vamos&space;denotar&space;$\widehat{F}(x_i)$&space;a&space;distribuição&space;empírica&space;estimada&space;dos&space;\textbf{p-values}&space;em&space;qualquer&space;ponto&space;$x_i\in(0,1)$.&space;Sob&space;$H_0$&space;os&space;\textbf{p-values}&space;são&space;uniformemente&space;distribuídos,&space;pelo&space;que&space;deve&space;verificar-se&space;$\widehat{F}(x_i)\approx&space;x_i$.&space;Uma&space;forma&space;expedita&space;para&space;investigar&space;as&space;propriedades&space;da&space;dimensão&space;de&space;um&space;teste&space;é&space;fazer&space;o&space;gráfico&space;de&space;$\widehat{F}(x_i)-x_i$&space;versus&space;$x_i$,&space;isto&space;é&space;o&space;que&space;Davidson&space;e&space;MacKinnon&space;(1998)&space;chama&space;de&space;\textbf{\emph{p-value&space;Discrepancy&space;Plot}}.&space;A&space;significância&space;estatística&space;das&space;discrepâncias&space;$\widehat{F}(x_i)-x_i$&space;pode&space;ser&space;aproximada&space;usando&space;a&space;distribuição&space;de&space;Kolmogorov-Smirnov.&space;Usando&space;estes&space;gráficos&space;é&space;possível&space;investigar&space;as&space;propriedades&space;da&space;dimensão&space;dos&space;testes,&space;não&space;só&space;num&space;conjunto&space;de&space;pontos&space;seleccionado,&space;mas&space;ao&space;longo&space;de&space;toda&space;a&space;distribuição&space;dos&space;p-values.&space;Para&space;a&space;análise&space;de&space;potência&space;dos&space;testes,&space;fazemos&space;o&space;gráfico&space;da&space;potência&space;versus&space;a&space;dimensão&space;actual.&space;Davidson&space;e&space;MacKinnon&space;(1998)&space;chamam&space;a&space;estes&space;gráficos&space;de&space;\textbf{\emph{Size-Power&space;Curves}}.&space;Colocando&space;a&space;potência&space;no&space;eixo&space;vertical&space;e&space;a&space;dimensão&space;actual&space;no&space;eixo&space;horizontal,&space;temos&space;uma&space;representação&space;gráfica&space;da&space;potência&space;para&space;qualquer&space;dimensão&space;desejada&space;do&space;teste.&space;Uma&space;linha&space;de&space;45º&space;é&space;tambêm&space;colocada&space;no&space;gráfico,&space;a&space;mesma&space;é&space;equivalente&space;à&space;curva&space;\emph{Power-Size}&space;de&space;um&space;teste&space;hipotético&space;cuja&space;potência&space;é&space;sempre&space;igual&space;à&space;dimensão,&space;esperamos&space;que&space;para&space;qualquer&space;valor&space;do&space;teste&space;que&space;a&space;curva&space;\emph{Size-Power}&space;do&space;nosso&space;teste&space;esteja&space;sempre&space;muito&space;acima&space;da&space;linha&space;de&space;45º.&space;Conclui-se&space;sem&space;dificuldade&space;que&space;o&space;ideal&space;seria&space;uma&space;curva&space;muito&space;próxima&space;de&space;1&space;para&space;qualquer&space;valor&space;da&space;\textbf{dimensão&space;actual}.&space;%======================================================================&space;\section{Análise&space;e&space;Interpretação&space;}&space;%======================================================================" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\inline&space;\large&space;%======================================================================&space;\chapter{Simulação&space;Monte&space;Carlo}&space;%&space;Write&space;in&space;your&space;own&space;chapter&space;title&space;\label{montecar}&space;%\lhead{&space;\emph{Introdução}}&space;%&space;Write&space;in&space;your&space;own&space;chapter&space;title&space;to&space;set&space;the&space;page&space;header&space;\fancyhead[LE,RO]{\textbf{\emph{\textcolor{ineblue}{Simulação&space;Monte&space;Carlo}}}}&space;\fancyhead[RE,LO]{\textbf{\textcolor{ineblue}\thepage}}&space;%======================================================================&space;%======================================================================&space;\section{Calibragem&space;da&space;Simulação}&space;%======================================================================&space;Em&space;todos&space;cenários&space;simulados&space;queremos&space;que&space;o&space;modelo&space;seja&space;o&space;mais&space;perfeito&space;possível,&space;em&space;que&space;as&space;únicas&space;distorções&space;do&space;teste&space;sejam&space;as&space;unicamente&space;causadas&space;pela&space;violação&space;das&space;hipóteses&space;de&space;ausência&space;de&space;autocorrelação&space;e/ou&space;heterocedasticidade.&space;Assim&space;impomos&space;que&space;$VAR(x_{it})=1$&space;e&space;que&space;$\sigma^2=\sigma_{\mu_i}^{2}&plus;\sigma_{v_{it}}^{2}=1$&space;em&space;todas&space;as&space;simulações,&space;além&space;do&space;mais,&space;a&space;contribuição&space;da&space;variância&space;dos&space;efeitos&space;individuais&space;para&space;a&space;variância&space;total&space;é&space;sempre&space;a&space;mesma&space;que&space;a&space;contribuição&space;dos&space;erros&space;idiossincráticos&space;logo&space;$\kappa=0.5$.&space;De&space;forma&space;a&space;calibrar&space;as&space;componentes&space;da&space;variável&space;\textbf{x},&space;e&space;porque&space;como&space;vimos&space;queremos&space;que&space;$VAR(x_{it})=VAR(\xi_{i})&plus;VAR(\xi_{it})=1$,&space;com&space;$VAR(\xi_{i})=\sigma_{\mu_i}^{2}=\kappa$,&space;$VAR(\xi_{it})=\sigma_{v_{it}}^{2}=\sigma_{\varphi_{it}}^{2}=(1-\kappa)$&space;e&space;$v_{it}\sim&space;N(0,\sigma_{v_{it}}^{2})$,&space;o&space;que&space;implica&space;que&space;existe&space;uma&space;relação&space;entre&space;as&space;variâncias&space;de&space;$\eta_i$&space;e&space;$\eta_{it}$&space;com&space;os&space;parâmetros&space;$\delta$&space;e&space;$\vartheta$,&space;respectivamente,&space;do&space;seguinte&space;modo:&space;\begin{equation*}&space;\sigma_{\eta_{it}}^2=(1-\vartheta^2)\sigma_{v_{it}}^{2}=(1-\vartheta^2)\sigma_{\varphi_{it}}^{2}\quad&space;\text{e}\quad&space;\sigma_{\eta_{i}}^2=(1-\delta^2)\sigma_{\mu_i}^{2}&space;\end{equation*}&space;e&space;garantimos&space;que&space;$VAR(x_{it})=1$&space;para&space;quaisquer&space;valores&space;de&space;$\delta$&space;e&space;$\vartheta$.&space;Em&space;todas&space;as&space;simulações&space;$\vartheta=0$\footnote{Não&space;queremos&space;a&space;existência&space;de&space;um&space;erro&space;de&space;medida&space;nos&space;modelos}&space;e&space;$\delta$&space;toma&space;os&space;valores&space;0,&space;0.25,&space;0.5,&space;0.75,&space;quando&space;$\delta=0$&space;temos&space;a&space;hipótese&space;nula&space;do&space;teste&space;de&space;Hausman&space;(1978),&space;onde,&space;ao&space;longo&space;dos&space;vários&space;cenários&space;simulados&space;podemos&space;aferir&space;do&space;comportamento&space;da&space;sua&space;\emph{dimensão}.&space;Se&space;$\delta\neq0$&space;temos&space;a&space;hipótese&space;alternativa&space;do&space;teste&space;que&space;é&space;usada&space;para&space;quantificar&space;a&space;sua&space;\emph{potência&space;}.&space;Com&space;esta&space;configuração&space;os&space;enviesamentos&space;ficam:\quad&space;$BIAS_B=\delta$&space;e&space;$BIAS_W=0$.&space;Para&space;estudar&space;o&space;comportamentos&space;do&space;teste&space;quando&space;existe&space;autocorrelação&space;no&space;erro&space;idiossincrático&space;adoptamos&space;um&space;modelo&space;tipo&space;(LILLARD&space;e&space;WILLIS&space;(1978)&space;CITAR),&space;que&space;já&space;foi&space;bastante&space;utilizado&space;por&space;Baltagi&space;e&space;outros(CITAR).&space;Juntamente&space;com&space;as&space;configuraçãoes&space;anteriores&space;temos:&space;$v_{it}=\rho&space;v_{it-1}&plus;\epsilon_{it}$,&space;com&space;$v_{i0}=\epsilon_{i0}/\sqrt{1-\rho^2}$,&space;$\epsilon_{it}\sim&space;N(0,\sigma_{\epsilon_{it}}^{2})$,&space;e&space;$v_{it}\sim&space;N(0,(1-\kappa))$,&space;e&space;temos:&space;$\sigma_{v_{it}}^2=\epsilon_{it}^{2}/(1-\rho^2)\Rightarrow\sigma_{\epsilon_{it}}^{2}=(1-\kappa)(1-\rho^2)$.&space;É&space;de&space;salientar&space;que&space;este&space;modelo&space;tem&space;três&space;fontes&space;de&space;``persistência''&space;conhecidas:&space;\begin{enumerate}&space;\item&space;Persistência&space;da&space;variável&space;explicativa&space;devida&space;à&space;sua&space;componente&space;\emph{Within}&space;que&space;tem&space;uma&space;sub-componente&space;definida&space;como&space;sendo&space;um&space;processo&space;$AR(\rho)$;&space;\item&space;Presença&space;do&space;efeito&space;individual&space;não&space;observado&space;(que&space;não&space;varia&space;com&space;o&space;tempo)&space;que&space;introduz&space;uma&space;fonte&space;de&space;persistência&space;fixa&space;em&space;todo&space;o&space;painel,&space;devido&space;à&space;presença&space;do&space;mesmo&space;indivíduo&space;em&space;todos&space;os&space;períodos&space;de&space;tempo;&space;\item&space;Aquela&space;associada&space;a&space;$\rho>0$,&space;o&space;que&space;induz&space;uma&space;persitência&space;transitória&space;devido&space;ao&space;carácter&space;estacionário&space;do&space;erro&space;idiossincrático,&space;em&space;todos&space;os&space;cenários&space;simulados&space;$\rho$&space;toma&space;valores&space;0,&space;0.25,&space;0.5,&space;0.75.&space;\end{enumerate}&space;%======================================================================&space;\subsection{Modelos&space;Simulados}&space;%======================================================================&space;O&space;modelo&space;base&space;(benchmark)&space;e&space;as&space;suas&space;variantes&space;com&space;autocorrelação&space;e/ou&space;heterocedasticidade&space;a&space;usar&space;nos&space;vários&space;cenários&space;simulados&space;é:\footnote{Consideramos&space;sempre&space;que&space;$\ell=1$&space;ou&space;seja&space;$\eta_{it}\sim&space;AR(1)$}:&space;\begin{itemize}&space;\item&space;i)&space;Benchmark&space;\begin{align*}&space;y_{it}&=5&plus;0.5x_{it}&plus;u_{it}\\&space;u_{it}&=\mu_i&plus;v_{it}\\&space;x_{it}&=\eta_i&plus;\delta\mu_i&plus;\omega_0\eta_{it}&plus;\omega_1\eta_{it-1}\\&space;\sigma^2&=\sigma_{\mu_i}^{2}&plus;\sigma_{v_{it}}^{2}=1\\&space;\kappa&=\frac{\sigma_{\mu_i}^{2}}{\sigma^2}\\&space;\eta_i&\sim&space;N(0,(1-\delta^2)\kappa)\\&space;\eta_{it}&\sim&space;N(0,(1-\kappa))\\&space;\mu_i&\sim&space;N(0,\kappa)\\&space;v_{it}&\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;ii)&space;Erro&space;idiossincrático&space;com&space;Autocorrelação&space;de&space;1\textordfeminine\xspace&space;ordem&space;\begin{align*}&space;v_{it}&=0.5v_{it-1}&plus;\epsilon_{it}\\&space;\epsilon_{it}&\sim&space;N(0,\sigma_{\epsilon_{it}}^{2})\\&space;\sigma_{\epsilon_{it}}^{2}&=(1-\kappa)(1-\rho^2)&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;iii)&space;Erro&space;idiossincrático&space;com&space;Heterocedasticidade&space;``cross-section''\footnote{Mais&space;conhecida&space;como&space;heterocedasticidade&space;de&space;painel.},&space;em&space;que&space;as&space;variâncias&space;mudam&space;com&space;a&space;unidade&space;``cross-section''&space;("`shift"'&space;na&space;variância),&space;ou&space;seja,&space;$\sigma_{v_{it}}^{2}$&space;é&space;definida&space;como:&space;\begin{align*}&space;\sigma_{v_{it}}^{2}&\sim&space;N(0,(1-\kappa))\quad\text{para}\quad&space;i=1,\cdots,\left\lfloor&space;N/2\right\rfloor\\&space;\sigma_{v_{it}}^{2}&\sim&space;N(0,1.5)\quad\text{para}\quad&space;i=\left\lfloor&space;N/2\right\rfloor,\cdots,N&space;\end{align*}&space;com&space;$\left\lfloor&space;q\right\rfloor$&space;a&space;parte&space;inteira&space;de&space;\textbf{q}.&space;\end{itemize}&space;\begin{itemize}&space;\item&space;iv)&space;Heterocedasticidade&space;causada&space;pela&space;variável&space;explicativa:&space;\begin{align*}&space;w_{it}=v_{it}(1&plus;\lambda&space;x_{it})\quad\text{com}\quad&space;v_{it}\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;v)&space;Heterocedasticidade&space;causada&space;pela&space;variável&space;$\mu_i$&space;\begin{align*}&space;w_{it}=v_{it}\mu_i\quad\text{com}\quad&space;v_{it}\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;\begin{itemize}&space;\item&space;vi)&space;Heterocedasticidade&space;causada&space;pela&space;componente&space;within&space;de&space;\textbf{X}:&space;\begin{align*}&space;w_{it}=v_{it}(1&plus;\lambda\eta_{it})\quad\text{com}\quad&space;v_{it}\sim&space;N(0,(1-\kappa))&space;\end{align*}&space;\end{itemize}&space;A&space;matriz&space;de&space;variâncias-covariâncias&space;da&space;componente&space;de&space;erro&space;com&space;heterocedasticidade&space;e/ou&space;autocorrelação&space;por&space;exemplo&space;para&space;\textbf{T=3}&space;vem:&space;\begin{equation*}&space;A_i=&space;\begin{pmatrix}&space;\sigma^{2}_{\mu}&plus;x_i\sigma^{2}_{v}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{1,2}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{1,3}&space;\\&space;\sigma^{2}_{\mu}&plus;\phi_{2,1}&space;&&space;\sigma^{2}_{\mu}&plus;x_i\sigma^{2}_{v}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{2,3}\\&space;\sigma^{2}_{\mu}&plus;\phi_{3,1}&space;&&space;\sigma^{2}_{\mu}&plus;\phi_{3,2}&space;&&space;\sigma^{2}_{\mu}&plus;x_i\sigma^{2}_{v}&space;\end{pmatrix}&space;\end{equation*}&space;\begin{equation*}&space;\Omega=&space;\begin{pmatrix}&space;A_1&space;&&space;0&space;&&space;0\\&space;0&space;&&space;A_2&space;&&space;0&space;\\&space;0&space;&&space;0&space;&&space;A_3&space;\end{pmatrix}&space;\end{equation*}&space;A&space;escolha&space;das&space;dimensões&space;CS&space;e&space;TS&space;para&space;as&space;nossas&space;simulações&space;segue&space;alguns&space;trabalhos&space;com&space;dados&space;de&space;painel&space;(nomeadamente&space;CITAR&space;autores&space;e&space;papers).&space;Ahn&space;e&space;Moon&space;(2001)&space;examinaram&space;teoricamente&space;as&space;propriedades&space;assimptóticas&space;dos&space;estimadores&space;Within,&space;GLS&space;e&space;do&space;teste&space;de&space;Hausman&space;standard&space;para&space;paineis&space;com&space;elevadas&space;unidades&space;CS&space;e&space;TS.&space;Os&space;autores&space;usaram&space;modelos&space;com&space;regressores&space;que&space;incluem&space;tendências&space;determinísticas&space;na&space;média&space;assim&space;como&space;regressores&space;invariantes&space;no&space;tempo.&space;Para&space;os&space;autores&space;o&space;estimador&space;Within&space;é&space;tão&space;eficiente&space;como&space;o&space;GLS&space;neste&space;contexto,&space;apesar&space;desta&space;equivalência&space;assimptótica,&space;a&space;estatística&space;de&space;Hausman&space;está&space;bem&space;definida&space;e&space;segue&space;assimptóticamente&space;uma&space;distribuição&space;do&space;$\chi^2$&space;sob&space;a&space;hipótese&space;de&space;efeitos&space;aleatórios.&space;Acabam&space;por&space;concluir&space;que&space;as&space;taxas&space;de&space;convergência&space;dos&space;estimadores&space;e&space;da&space;estatística&space;de&space;teste&space;são&space;sensiveis&space;aos&space;DGP's&space;usados.&space;Apesar&space;de&space;existirem&space;diferentes&space;taxas&space;de&space;convergência,&space;os&space;estimadores&space;são&space;consistentes&space;e&space;assimptóticamente&space;normais&space;sob&space;a&space;hipótese&space;de&space;efeitos&space;aleatórios.&space;A&space;estatística&space;de&space;Hausman&space;Standard&space;está&space;bem&space;definida&space;apesar&space;de&space;os&space;dois&space;estimadores&space;serem&space;assimptóticamente&space;idênticos&space;sob&space;uma&space;sequência&space;de&space;hipóteses&space;alternativas.&space;Assim&space;a&space;lição&space;que&space;se&space;retira&space;deste&space;estudo&space;é&space;que&space;a&space;teoria&space;assimptótica&space;quando&space;$N,T\rightarrow\infty$&space;é&space;muito&space;mais&space;sensível&space;aos&space;DGP's&space;usados&space;do&space;que&space;quando&space;$N\rightarrow\infty$&space;ou&space;$T\rightarrow\infty$.&space;Para&space;o&space;nosso&space;estudo&space;resolvemos&space;usar&space;as&space;seguintes&space;dimensões:&space;N=(25,&space;50,&space;100)&space;e&space;T=(5,&space;10,&space;20,&space;30).&space;No&space;que&space;respeita&space;à&space;estimação&space;das&space;variâncias&space;da&space;componente&space;de&space;erro&space;usamos&space;o&space;método&space;de&space;Ammemyia\footnote{O&space;package&space;``plm''&space;do&space;\normalsize{\R}&space;tem&space;um&space;pequeno&space;bug&space;ao&space;dar&space;erro&space;no&space;teste&space;de&space;hausman&space;quando&space;as&space;variâncias&space;são&space;negativas&space;e&space;usamos&space;o&space;método&space;implementado&space;por&space;defeito:&space;Swamy&space;e&space;Arora.}&space;em&space;todas&space;as&space;simulações,&space;suportamos&space;esta&space;escolha&space;no&space;estudo&space;de&space;Maddala&space;e&space;Mount&space;(1973)&space;que&space;mostraram&space;através&space;de&space;simulação&space;que&space;a&space;escolha&space;de&space;um&space;particular&space;método&space;para&space;as&space;estimar&space;não&space;tem&space;impactos&space;significativos&space;nas&space;propriedades&space;dos&space;estimadores&space;dos&space;coeficientes&space;no&space;segundo&space;passo&space;do&space;FGLS&space;(veja-se&space;tambêm&space;Taylor&space;(1980)&space;que&space;dá&space;um&space;exemplo&space;teórico),&space;isto&space;não&space;quer&space;dizer&space;que&space;substituindo&space;o&space;verdadeiro&space;valor&space;de&space;$\theta$&space;por&space;uma&space;sua&space;estimativa&space;não&space;tenha&space;consequências.&space;Não&space;afecta&space;as&space;propriedades&space;assimptóticas&space;do&space;FGLS&space;,&space;mas&space;tem&space;influência&space;nas&space;suas&space;propriedades&space;em&space;amostras&space;finitas,&space;o&space;GLS&space;é&space;não&space;enviesado,&space;o&space;FGLS&space;não&space;o&space;é,&space;a&space;não&space;ser&space;em&space;circunstâncias&space;muito&space;particulares(&space;ver&space;Baltagi,&space;Matyas,&space;Sevestre).&space;Recentemente&space;Vasnev&space;(2009)&space;estudou&space;a&space;sensibilidade&space;dos&space;estimadores&space;de&space;efeitos&space;aleatórios&space;num&space;modelo&space;``One-way''&space;com&space;componentes&space;no&space;erro&space;ao&space;estimador&space;do&space;primeiro&space;passo&space;das&space;variâncias,&space;ilustrando-a&space;com&space;um&space;pequeno&space;estudo&space;de&space;simulação&space;e&space;mostra&space;que&space;o&space;enviesamento&space;e&space;as&space;variâncias&space;dos&space;estimadores&space;do&space;primeiro&space;e&space;segundo&space;passo&space;estão&space;ligados&space;através&space;de&space;uma&space;estatística&space;de&space;sensibilidade.&space;Conjuntamente&space;com&space;a&space;independência&space;do&space;estimador&space;do&space;primeiro&space;passo,&space;a&space;estatística&space;de&space;sensibilidade&space;tem&space;propriedades&space;específicas,&space;o&space;que&space;faz&space;com&space;que&space;o&space;estimador&space;do&space;segundo&space;passo&space;seja&space;independente&space;do&space;enviesamento&space;do&space;estimador&space;do&space;primeiro&space;passo,&space;o&space;que&space;torna&space;a&space;variância&space;do&space;estimador&space;do&space;segundo&space;passo&space;insensível&space;aos&space;ganhos&space;de&space;eficiencia&space;do&space;estimador&space;do&space;primeiro&space;passo.&space;Este&space;estudo&space;explica&space;as&space;conclusões&space;de&space;Maddala&space;e&space;mount&space;(1973)&space;e&space;por&space;conseguinte&space;a&space;nossa&space;escolha&space;do&space;método&space;para&space;estimar&space;as&space;variâncias&space;da&space;componente&space;de&space;erro.&space;%======================================================================&space;\section{Apresentação&space;dos&space;Resultados}&space;%&space;Write&space;in&space;your&space;own&space;chapter&space;title&space;%======================================================================&space;%======================================================================&space;\subsection{Dimensão&space;e&space;Potência&space;de&space;um&space;Teste}&space;%======================================================================&space;É&space;sabido&space;da&space;teoria&space;estatística&space;elementar&space;que&space;a&space;\textbf{\emph{dimensão}}&space;de&space;um&space;teste&space;assenta&space;na&space;taxa&space;de&space;rejeição&space;da&space;hipótese&space;nula&space;($H_0$)&space;quando&space;esta&space;é&space;verdadeira,&space;e&space;a&space;\textbf{\emph{potência}}&space;implica&space;a&space;sua&space;taxa&space;de&space;rejeição&space;quando&space;a&space;hipótese&space;alternativa&space;é&space;verdadeira.&space;Normalmente&space;definimos&space;a&space;dimensão&space;do&space;teste&space;num&space;nível&space;de&space;significância&space;específico:&space;$\alpha$,&space;por&space;exemplo&space;o&space;valor&space;crítico&space;a&space;5\%&space;para&space;uma&space;distribuição&space;Normal&space;(teste&space;bilateral)&space;é&space;igual&space;a&space;1.95.&space;Basicamente&space;a&space;ideia&space;é&space;fazer&space;uma&space;decisão&space;errada&space;a&space;um&space;nível&space;de&space;5\%.&space;definir&space;uma&space;dimensão&space;pequena&space;quer&space;dizer&space;que&space;queremos&space;ser&space;mais&space;conservadores&space;ou&space;não&space;queremos&space;errar&space;de&space;todo,&space;mas&space;ao&space;mesmo&space;tempo&space;tambêm&space;implica&space;que&space;a&space;potência&space;do&space;teste&space;virá&space;reduzida.&space;Inicialmente&space;definimos&space;uma&space;dimensão&space;para&space;o&space;teste&space;de&space;$\alpha\%$,&space;contudo&space;(especialmente&space;em&space;amostras&space;finitas),&space;um&space;teste&space;não&space;dá&space;exactamente&space;a&space;dimensão&space;pretendida&space;de&space;$\alpha\%$.&space;Se&space;um&space;teste&space;\emph{\textbf{sobre-rejeita}}&space;$H_0$&space;quando&space;esta&space;é&space;verdadeira,&space;dizemos&space;que&space;o&space;teste&space;sofre&space;de&space;\textbf{\emph{Oversize-Distortion}}.&space;O&space;caso&space;oposto&space;é&space;o&space;de&space;\textbf{\emph{Undesize-Distortion}}.&space;Geralmente&space;um&space;teste&space;que&space;\textbf{\emph{sub-rejeita}}&space;é&space;aceitável&space;desde&space;que&space;este&space;simplesmente&space;implique&space;cometer&space;menos&space;erros.&space;O&space;problema&space;de&space;\textbf{\emph{sobre-rejeição}}&space;torna-se&space;sério,&space;dado&space;que&space;o&space;teste&space;usualmente&space;rejeita&space;$H_0$&space;muitas&space;mais&space;vezes&space;que&space;o&space;necessário,&space;mesmo&space;sendo&space;esta&space;verdadeira.&space;%======================================================================&space;\subsection{Tabelas&space;ou&space;Gráficos?}\label{tabougraf}&space;%======================================================================&space;Uma&space;das&space;maiores&space;dificuldades&space;com&space;que&space;nos&space;deparamos&space;quando&space;fazemos&space;estudos&space;de&space;simulação&space;para&space;estudar&space;o&space;comportamento&space;de&space;testes&space;estatísticos,&space;além&space;dos&space;problemas&space;de&space;implementação&space;computacional,&space;é&space;o&space;de&space;sintetizar&space;e&space;interpretar&space;os&space;resultados&space;obtidos.&space;Podemos&space;usar&space;tabelas,&space;mas&space;com&space;a&space;quantidade&space;de&space;parâmetros&space;que&space;podem&space;variar&space;e&space;a&space;sempre&space;imposta&space;limitação&space;de&space;páginas&space;para&space;escrever&space;um&space;artigo&space;de&space;jornal&space;ou&space;mesmo&space;uma&space;dissertação&space;de&space;mestrado,&space;as&space;conclusões&space;a&space;retirar&space;das&space;tabelas&space;são&space;complicadas.&space;A&space;solução&space;é&space;a&space;de&space;apresentar&space;os&space;resultados&space;graficamente,&space;permitindo&space;uma&space;análise&space;expedita&space;e&space;intuitiva&space;dos&space;mesmos.&space;Os&space;resultados&space;obtidos&space;na&space;simulação&space;são&space;apresentados&space;usando&space;o&space;método&space;gráfico&space;explicado&space;no&space;excelente&space;trabalho&space;de&space;Davidson&space;e&space;MacKinnon&space;(1998).&space;Vamos&space;denotar&space;$\widehat{F}(x_i)$&space;a&space;distribuição&space;empírica&space;estimada&space;dos&space;\textbf{p-values}&space;em&space;qualquer&space;ponto&space;$x_i\in(0,1)$.&space;Sob&space;$H_0$&space;os&space;\textbf{p-values}&space;são&space;uniformemente&space;distribuídos,&space;pelo&space;que&space;deve&space;verificar-se&space;$\widehat{F}(x_i)\approx&space;x_i$.&space;Uma&space;forma&space;expedita&space;para&space;investigar&space;as&space;propriedades&space;da&space;dimensão&space;de&space;um&space;teste&space;é&space;fazer&space;o&space;gráfico&space;de&space;$\widehat{F}(x_i)-x_i$&space;versus&space;$x_i$,&space;isto&space;é&space;o&space;que&space;Davidson&space;e&space;MacKinnon&space;(1998)&space;chama&space;de&space;\textbf{\emph{p-value&space;Discrepancy&space;Plot}}.&space;A&space;significância&space;estatística&space;das&space;discrepâncias&space;$\widehat{F}(x_i)-x_i$&space;pode&space;ser&space;aproximada&space;usando&space;a&space;distribuição&space;de&space;Kolmogorov-Smirnov.&space;Usando&space;estes&space;gráficos&space;é&space;possível&space;investigar&space;as&space;propriedades&space;da&space;dimensão&space;dos&space;testes,&space;não&space;só&space;num&space;conjunto&space;de&space;pontos&space;seleccionado,&space;mas&space;ao&space;longo&space;de&space;toda&space;a&space;distribuição&space;dos&space;p-values.&space;Para&space;a&space;análise&space;de&space;potência&space;dos&space;testes,&space;fazemos&space;o&space;gráfico&space;da&space;potência&space;versus&space;a&space;dimensão&space;actual.&space;Davidson&space;e&space;MacKinnon&space;(1998)&space;chamam&space;a&space;estes&space;gráficos&space;de&space;\textbf{\emph{Size-Power&space;Curves}}.&space;Colocando&space;a&space;potência&space;no&space;eixo&space;vertical&space;e&space;a&space;dimensão&space;actual&space;no&space;eixo&space;horizontal,&space;temos&space;uma&space;representação&space;gráfica&space;da&space;potência&space;para&space;qualquer&space;dimensão&space;desejada&space;do&space;teste.&space;Uma&space;linha&space;de&space;45º&space;é&space;tambêm&space;colocada&space;no&space;gráfico,&space;a&space;mesma&space;é&space;equivalente&space;à&space;curva&space;\emph{Power-Size}&space;de&space;um&space;teste&space;hipotético&space;cuja&space;potência&space;é&space;sempre&space;igual&space;à&space;dimensão,&space;esperamos&space;que&space;para&space;qualquer&space;valor&space;do&space;teste&space;que&space;a&space;curva&space;\emph{Size-Power}&space;do&space;nosso&space;teste&space;esteja&space;sempre&space;muito&space;acima&space;da&space;linha&space;de&space;45º.&space;Conclui-se&space;sem&space;dificuldade&space;que&space;o&space;ideal&space;seria&space;uma&space;curva&space;muito&space;próxima&space;de&space;1&space;para&space;qualquer&space;valor&space;da&space;\textbf{dimensão&space;actual}.&space;%======================================================================&space;\section{Análise&space;e&space;Interpretação&space;}&space;%======================================================================" title="\large %====================================================================== \chapter{Simulação Monte Carlo} % Write in your own chapter title \label{montecar} %\lhead{ \emph{Introdução}} % Write in your own chapter title to set the page header \fancyhead[LE,RO]{\textbf{\emph{\textcolor{ineblue}{Simulação Monte Carlo}}}} \fancyhead[RE,LO]{\textbf{\textcolor{ineblue}\thepage}} %====================================================================== %====================================================================== \section{Calibragem da Simulação} %====================================================================== Em todos cenários simulados queremos que o modelo seja o mais perfeito possível, em que as únicas distorções do teste sejam as unicamente causadas pela violação das hipóteses de ausência de autocorrelação e/ou heterocedasticidade. Assim impomos que $VAR(x_{it})=1$ e que $\sigma^2=\sigma_{\mu_i}^{2}+\sigma_{v_{it}}^{2}=1$ em todas as simulações, além do mais, a contribuição da variância dos efeitos individuais para a variância total é sempre a mesma que a contribuição dos erros idiossincráticos logo $\kappa=0.5$. De forma a calibrar as componentes da variável \textbf{x}, e porque como vimos queremos que $VAR(x_{it})=VAR(\xi_{i})+VAR(\xi_{it})=1$, com $VAR(\xi_{i})=\sigma_{\mu_i}^{2}=\kappa$, $VAR(\xi_{it})=\sigma_{v_{it}}^{2}=\sigma_{\varphi_{it}}^{2}=(1-\kappa)$ e $v_{it}\sim N(0,\sigma_{v_{it}}^{2})$, o que implica que existe uma relação entre as variâncias de $\eta_i$ e $\eta_{it}$ com os parâmetros $\delta$ e $\vartheta$, respectivamente, do seguinte modo: \begin{equation*} \sigma_{\eta_{it}}^2=(1-\vartheta^2)\sigma_{v_{it}}^{2}=(1-\vartheta^2)\sigma_{\varphi_{it}}^{2}\quad \text{e}\quad \sigma_{\eta_{i}}^2=(1-\delta^2)\sigma_{\mu_i}^{2} \end{equation*} e garantimos que $VAR(x_{it})=1$ para quaisquer valores de $\delta$ e $\vartheta$. Em todas as simulações $\vartheta=0$\footnote{Não queremos a existência de um erro de medida nos modelos} e $\delta$ toma os valores 0, 0.25, 0.5, 0.75, quando $\delta=0$ temos a hipótese nula do teste de Hausman (1978), onde, ao longo dos vários cenários simulados podemos aferir do comportamento da sua \emph{dimensão}. Se $\delta\neq0$ temos a hipótese alternativa do teste que é usada para quantificar a sua \emph{potência }. Com esta configuração os enviesamentos ficam:\quad $BIAS_B=\delta$ e $BIAS_W=0$. Para estudar o comportamentos do teste quando existe autocorrelação no erro idiossincrático adoptamos um modelo tipo (LILLARD e WILLIS (1978) CITAR), que já foi bastante utilizado por Baltagi e outros(CITAR). Juntamente com as configuraçãoes anteriores temos: $v_{it}=\rho v_{it-1}+\epsilon_{it}$, com $v_{i0}=\epsilon_{i0}/\sqrt{1-\rho^2}$, $\epsilon_{it}\sim N(0,\sigma_{\epsilon_{it}}^{2})$, e $v_{it}\sim N(0,(1-\kappa))$, e temos: $\sigma_{v_{it}}^2=\epsilon_{it}^{2}/(1-\rho^2)\Rightarrow\sigma_{\epsilon_{it}}^{2}=(1-\kappa)(1-\rho^2)$. É de salientar que este modelo tem três fontes de ``persistência'' conhecidas: \begin{enumerate} \item Persistência da variável explicativa devida à sua componente \emph{Within} que tem uma sub-componente definida como sendo um processo $AR(\rho)$; \item Presença do efeito individual não observado (que não varia com o tempo) que introduz uma fonte de persistência fixa em todo o painel, devido à presença do mesmo indivíduo em todos os períodos de tempo; \item Aquela associada a $\rho>0$, o que induz uma persitência transitória devido ao carácter estacionário do erro idiossincrático, em todos os cenários simulados $\rho$ toma valores 0, 0.25, 0.5, 0.75. \end{enumerate} %====================================================================== \subsection{Modelos Simulados} %====================================================================== O modelo base (benchmark) e as suas variantes com autocorrelação e/ou heterocedasticidade a usar nos vários cenários simulados é:\footnote{Consideramos sempre que $\ell=1$ ou seja $\eta_{it}\sim AR(1)$}: \begin{itemize} \item i) Benchmark \begin{align*} y_{it}&=5+0.5x_{it}+u_{it}\\ u_{it}&=\mu_i+v_{it}\\ x_{it}&=\eta_i+\delta\mu_i+\omega_0\eta_{it}+\omega_1\eta_{it-1}\\ \sigma^2&=\sigma_{\mu_i}^{2}+\sigma_{v_{it}}^{2}=1\\ \kappa&=\frac{\sigma_{\mu_i}^{2}}{\sigma^2}\\ \eta_i&\sim N(0,(1-\delta^2)\kappa)\\ \eta_{it}&\sim N(0,(1-\kappa))\\ \mu_i&\sim N(0,\kappa)\\ v_{it}&\sim N(0,(1-\kappa)) \end{align*} \end{itemize} \begin{itemize} \item ii) Erro idiossincrático com Autocorrelação de 1\textordfeminine\xspace ordem \begin{align*} v_{it}&=0.5v_{it-1}+\epsilon_{it}\\ \epsilon_{it}&\sim N(0,\sigma_{\epsilon_{it}}^{2})\\ \sigma_{\epsilon_{it}}^{2}&=(1-\kappa)(1-\rho^2) \end{align*} \end{itemize} \begin{itemize} \item iii) Erro idiossincrático com Heterocedasticidade ``cross-section''\footnote{Mais conhecida como heterocedasticidade de painel.}, em que as variâncias mudam com a unidade ``cross-section'' ("`shift"' na variância), ou seja, $\sigma_{v_{it}}^{2}$ é definida como: \begin{align*} \sigma_{v_{it}}^{2}&\sim N(0,(1-\kappa))\quad\text{para}\quad i=1,\cdots,\left\lfloor N/2\right\rfloor\\ \sigma_{v_{it}}^{2}&\sim N(0,1.5)\quad\text{para}\quad i=\left\lfloor N/2\right\rfloor,\cdots,N \end{align*} com $\left\lfloor q\right\rfloor$ a parte inteira de \textbf{q}. \end{itemize} \begin{itemize} \item iv) Heterocedasticidade causada pela variável explicativa: \begin{align*} w_{it}=v_{it}(1+\lambda x_{it})\quad\text{com}\quad v_{it}\sim N(0,(1-\kappa)) \end{align*} \end{itemize} \begin{itemize} \item v) Heterocedasticidade causada pela variável $\mu_i$ \begin{align*} w_{it}=v_{it}\mu_i\quad\text{com}\quad v_{it}\sim N(0,(1-\kappa)) \end{align*} \end{itemize} \begin{itemize} \item vi) Heterocedasticidade causada pela componente within de \textbf{X}: \begin{align*} w_{it}=v_{it}(1+\lambda\eta_{it})\quad\text{com}\quad v_{it}\sim N(0,(1-\kappa)) \end{align*} \end{itemize} A matriz de variâncias-covariâncias da componente de erro com heterocedasticidade e/ou autocorrelação por exemplo para \textbf{T=3} vem: \begin{equation*} A_i= \begin{pmatrix} \sigma^{2}_{\mu}+x_i\sigma^{2}_{v} & \sigma^{2}_{\mu}+\phi_{1,2} & \sigma^{2}_{\mu}+\phi_{1,3} \\ \sigma^{2}_{\mu}+\phi_{2,1} & \sigma^{2}_{\mu}+x_i\sigma^{2}_{v} & \sigma^{2}_{\mu}+\phi_{2,3}\\ \sigma^{2}_{\mu}+\phi_{3,1} & \sigma^{2}_{\mu}+\phi_{3,2} & \sigma^{2}_{\mu}+x_i\sigma^{2}_{v} \end{pmatrix} \end{equation*} \begin{equation*} \Omega= \begin{pmatrix} A_1 & 0 & 0\\ 0 & A_2 & 0 \\ 0 & 0 & A_3 \end{pmatrix} \end{equation*} A escolha das dimensões CS e TS para as nossas simulações segue alguns trabalhos com dados de painel (nomeadamente CITAR autores e papers). Ahn e Moon (2001) examinaram teoricamente as propriedades assimptóticas dos estimadores Within, GLS e do teste de Hausman standard para paineis com elevadas unidades CS e TS. Os autores usaram modelos com regressores que incluem tendências determinísticas na média assim como regressores invariantes no tempo. Para os autores o estimador Within é tão eficiente como o GLS neste contexto, apesar desta equivalência assimptótica, a estatística de Hausman está bem definida e segue assimptóticamente uma distribuição do $\chi^2$ sob a hipótese de efeitos aleatórios. Acabam por concluir que as taxas de convergência dos estimadores e da estatística de teste são sensiveis aos DGP's usados. Apesar de existirem diferentes taxas de convergência, os estimadores são consistentes e assimptóticamente normais sob a hipótese de efeitos aleatórios. A estatística de Hausman Standard está bem definida apesar de os dois estimadores serem assimptóticamente idênticos sob uma sequência de hipóteses alternativas. Assim a lição que se retira deste estudo é que a teoria assimptótica quando $N,T\rightarrow\infty$ é muito mais sensível aos DGP's usados do que quando $N\rightarrow\infty$ ou $T\rightarrow\infty$. Para o nosso estudo resolvemos usar as seguintes dimensões: N=(25, 50, 100) e T=(5, 10, 20, 30). No que respeita à estimação das variâncias da componente de erro usamos o método de Ammemyia\footnote{O package ``plm'' do \normalsize{\R} tem um pequeno bug ao dar erro no teste de hausman quando as variâncias são negativas e usamos o método implementado por defeito: Swamy e Arora.} em todas as simulações, suportamos esta escolha no estudo de Maddala e Mount (1973) que mostraram através de simulação que a escolha de um particular método para as estimar não tem impactos significativos nas propriedades dos estimadores dos coeficientes no segundo passo do FGLS (veja-se tambêm Taylor (1980) que dá um exemplo teórico), isto não quer dizer que substituindo o verdadeiro valor de $\theta$ por uma sua estimativa não tenha consequências. Não afecta as propriedades assimptóticas do FGLS , mas tem influência nas suas propriedades em amostras finitas, o GLS é não enviesado, o FGLS não o é, a não ser em circunstâncias muito particulares( ver Baltagi, Matyas, Sevestre). Recentemente Vasnev (2009) estudou a sensibilidade dos estimadores de efeitos aleatórios num modelo ``One-way'' com componentes no erro ao estimador do primeiro passo das variâncias, ilustrando-a com um pequeno estudo de simulação e mostra que o enviesamento e as variâncias dos estimadores do primeiro e segundo passo estão ligados através de uma estatística de sensibilidade. Conjuntamente com a independência do estimador do primeiro passo, a estatística de sensibilidade tem propriedades específicas, o que faz com que o estimador do segundo passo seja independente do enviesamento do estimador do primeiro passo, o que torna a variância do estimador do segundo passo insensível aos ganhos de eficiencia do estimador do primeiro passo. Este estudo explica as conclusões de Maddala e mount (1973) e por conseguinte a nossa escolha do método para estimar as variâncias da componente de erro. %====================================================================== \section{Apresentação dos Resultados} % Write in your own chapter title %====================================================================== %====================================================================== \subsection{Dimensão e Potência de um Teste} %====================================================================== É sabido da teoria estatística elementar que a \textbf{\emph{dimensão}} de um teste assenta na taxa de rejeição da hipótese nula ($H_0$) quando esta é verdadeira, e a \textbf{\emph{potência}} implica a sua taxa de rejeição quando a hipótese alternativa é verdadeira. Normalmente definimos a dimensão do teste num nível de significância específico: $\alpha$, por exemplo o valor crítico a 5\% para uma distribuição Normal (teste bilateral) é igual a 1.95. Basicamente a ideia é fazer uma decisão errada a um nível de 5\%. definir uma dimensão pequena quer dizer que queremos ser mais conservadores ou não queremos errar de todo, mas ao mesmo tempo tambêm implica que a potência do teste virá reduzida. Inicialmente definimos uma dimensão para o teste de $\alpha\%$, contudo (especialmente em amostras finitas), um teste não dá exactamente a dimensão pretendida de $\alpha\%$. Se um teste \emph{\textbf{sobre-rejeita}} $H_0$ quando esta é verdadeira, dizemos que o teste sofre de \textbf{\emph{Oversize-Distortion}}. O caso oposto é o de \textbf{\emph{Undesize-Distortion}}. Geralmente um teste que \textbf{\emph{sub-rejeita}} é aceitável desde que este simplesmente implique cometer menos erros. O problema de \textbf{\emph{sobre-rejeição}} torna-se sério, dado que o teste usualmente rejeita $H_0$ muitas mais vezes que o necessário, mesmo sendo esta verdadeira. %====================================================================== \subsection{Tabelas ou Gráficos?}\label{tabougraf} %====================================================================== Uma das maiores dificuldades com que nos deparamos quando fazemos estudos de simulação para estudar o comportamento de testes estatísticos, além dos problemas de implementação computacional, é o de sintetizar e interpretar os resultados obtidos. Podemos usar tabelas, mas com a quantidade de parâmetros que podem variar e a sempre imposta limitação de páginas para escrever um artigo de jornal ou mesmo uma dissertação de mestrado, as conclusões a retirar das tabelas são complicadas. A solução é a de apresentar os resultados graficamente, permitindo uma análise expedita e intuitiva dos mesmos. Os resultados obtidos na simulação são apresentados usando o método gráfico explicado no excelente trabalho de Davidson e MacKinnon (1998). Vamos denotar $\widehat{F}(x_i)$ a distribuição empírica estimada dos \textbf{p-values} em qualquer ponto $x_i\in(0,1)$. Sob $H_0$ os \textbf{p-values} são uniformemente distribuídos, pelo que deve verificar-se $\widehat{F}(x_i)\approx x_i$. Uma forma expedita para investigar as propriedades da dimensão de um teste é fazer o gráfico de $\widehat{F}(x_i)-x_i$ versus $x_i$, isto é o que Davidson e MacKinnon (1998) chama de \textbf{\emph{p-value Discrepancy Plot}}. A significância estatística das discrepâncias $\widehat{F}(x_i)-x_i$ pode ser aproximada usando a distribuição de Kolmogorov-Smirnov. Usando estes gráficos é possível investigar as propriedades da dimensão dos testes, não só num conjunto de pontos seleccionado, mas ao longo de toda a distribuição dos p-values. Para a análise de potência dos testes, fazemos o gráfico da potência versus a dimensão actual. Davidson e MacKinnon (1998) chamam a estes gráficos de \textbf{\emph{Size-Power Curves}}. Colocando a potência no eixo vertical e a dimensão actual no eixo horizontal, temos uma representação gráfica da potência para qualquer dimensão desejada do teste. Uma linha de 45º é tambêm colocada no gráfico, a mesma é equivalente à curva \emph{Power-Size} de um teste hipotético cuja potência é sempre igual à dimensão, esperamos que para qualquer valor do teste que a curva \emph{Size-Power} do nosso teste esteja sempre muito acima da linha de 45º. Conclui-se sem dificuldade que o ideal seria uma curva muito próxima de 1 para qualquer valor da \textbf{dimensão actual}. %====================================================================== \section{Análise e Interpretação } %======================================================================" /></a>
